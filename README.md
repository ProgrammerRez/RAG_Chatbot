# ğŸ“„ RAG QnA with Document Support

[ğŸš€ Live Demo](https://rag-chatbot-session-based-pdf-support.streamlit.app)  

A **professional, session-based RAG (Retrieval-Augmented Generation) chatbot** that allows users to upload PDF documents and ask questions. Powered by **Groq + LangChain**, this tool supports both standard and scanned PDFs (via OCR) and provides context-aware answers in real time.  

---

## âœ¨ Features

- **ğŸ“‚ PDF Upload & Processing**  
  Upload multiple PDFs for analysis. Scanned PDFs are automatically converted to text using OCR.

- **ğŸ’¬ Session-Based Conversations**  
  Maintain separate chat sessions with persistent memory for a seamless question-answer experience.

- **ğŸ§  Contextual Q&A with RAG**  
  Uses FAISS vector store and embeddings to retrieve the most relevant document snippets before generating answers.

- **ğŸ¤– Groq-Powered LLM Integration**  
  Supports multiple models, including `qwen/qwen3-32b`, `gemma2-9b-it`, and `openai/gpt-oss-120b`.

- **ğŸ–¥ Interactive Chat Interface**  
  Ask questions about your documents and get precise, contextual answers along with retrieved content previews.

- **âš™ï¸ Customizable LLM Settings**  
  Control model selection, temperature, and session management directly from the sidebar.

---

## ğŸ›  How It Works

1. **ğŸ“¤ Upload PDFs**  
   The app accepts both standard and scanned PDFs. For scanned PDFs, **Tesseract OCR** extracts text.

2. **âœ‚ï¸ Text Splitting & Embeddings**  
   Documents are split into smaller chunks for effective retrieval. Embeddings are generated using **HuggingFace sentence-transformers**.

3. **ğŸ“š Vector Store Initialization**  
   Chunks are stored in an **FAISS vector store** for similarity-based retrieval.

4. **ğŸ”„ RAG Graph Pipeline**  
   - **Retrieve:** Find the most relevant document chunks.  
   - **Generate:** Use the LLM to answer questions based on retrieved context.

5. **ğŸ’¬ Chat Interface**  
   Users can interact in a session-based chat interface and see both answers and the relevant document snippets.

---

## âš¡ Installation

```bash
git clone <repository-url>
cd rag-chatbot-session-based-pdf-support
pip install -r requirements.txt
streamlit run app.py
````

**Requirements:**

* ğŸ Python â‰¥ 3.10
* ğŸ–¥ Streamlit
* ğŸ“¦ LangChain & LangGraph
* ğŸ”‘ Groq API Key
* ğŸ“„ PyPDF2, pdf2image, pytesseract
* âš¡ FAISS & HuggingFace Transformers

---

## âš™ï¸ Configuration

1. **ğŸ”‘ Groq API Key:**
   Enter your API key in the sidebar. Get one [here](https://console.groq.com/keys).

2. **ğŸ§© Select Model:**
   Choose the desired LLM for generating answers.

3. **ğŸŒ¡ Adjust Temperature:**
   Control randomness in responses (0.0 = deterministic, 2.0 = creative).

4. **ğŸ—‚ Session Management:**

   * â• Create a new session or select an existing one.
   * ğŸ’¾ Each session retains chat history and memory for context-aware responses.

---

## ğŸš€ Usage

1. ğŸ“‚ Upload one or more PDF files.
2. âš¡ Click **Process Files** to index documents.
3. ğŸ’¬ Ask questions in the chat input.
4. ğŸ“– View retrieved context and AI-generated answers.
5. ğŸ”„ Switch or create sessions for different topics or users.

---

## ğŸ›  Technologies Used

* **LangChain & LangGraph:** RAG workflow orchestration
* **Groq LLM:** High-performance language model inference
* **FAISS:** Efficient similarity search for document chunks
* **HuggingFace Embeddings:** Convert text to dense vectors
* **Tesseract OCR:** Convert scanned PDFs to text
* **Streamlit:** Frontend interface for interactive chat

---

## ğŸŒ Demo

Access the live demo here: [RAG Chatbot with Session-Based PDF Support](https://rag-chatbot-session-based-pdf-support.streamlit.app)

